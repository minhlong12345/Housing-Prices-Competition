{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nIn the update version 3, I used the pipeline to systematically solve the problem. In addition, I will explore how to solve numerical and categorical variables.\n\nSo, in the dataset we can see it has two kinds: numerical variables (with type are int64 and float64), categorical variables (with type is object). In this version we do not care about outliers and skew of dataset, we only talk about how to use pipeline to manage preprocessing and model steps.\n\nOK. let's go!\n"},{"metadata":{},"cell_type":"markdown","source":"## STEP 1: Find the path of input and output\n\nThis is important for use dataset and output data. When we have created a model, we need to use it to handle complex situations require multiple models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this code to see the path of input and output\nimport os\nprint('The path file input:')\nfor dirname, _,filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname,filename))\n\nprint('The path file output:')\nfor dirname1, _,filenames1 in os.walk('/kaggle/working'):\n    for filename1 in filenames1:\n        print(os.path.join(dirname1,filename1))","execution_count":1,"outputs":[{"output_type":"stream","text":"The path file input:\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv\nThe path file output:\n/kaggle/working/__notebook_source__.ipynb\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## STEP 2: Exploratory data analysis\nIn this step we need:\n1. Preminary observations: in this part we have to know: \n*size, how many columns with numerical and categorical*\n2. Read file and split it into seperate part"},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Preminary observations"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Call the libraries \nimport pandas as pd\n\n# Path of the file to read.\nfile_path_home = '/kaggle/input/home-data-for-ml-course/train.csv'\nfile_path_test = '/kaggle/input/home-data-for-ml-course/test.csv'\nhome_train_data = pd.read_csv(file_path_home,index_col = 'Id')\nhome_test_data = pd.read_csv(file_path_test, index_col = 'Id')\ntrain_data = home_train_data.copy() # copy dataset for process without change it  \ntest_data = home_test_data.copy()\n\n# display data\nprint(test_data.shape)\nprint(train_data.shape)\nprint('numeric cloumns {} '\n      .format(train_data.select_dtypes(exclude=['object']).columns))\nprint('len of numeric cloumns {} '\n      .format(len(train_data.select_dtypes(exclude=['object']).columns)))\nprint('categoric cloumns {} '\n      .format(train_data.select_dtypes(include=['object']).columns))\nprint('len of categoric cloumns {} '\n      .format(len(train_data.select_dtypes(include=['object']).columns)))","execution_count":2,"outputs":[{"output_type":"stream","text":"(1459, 79)\n(1460, 80)\nnumeric cloumns Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold', 'SalePrice'],\n      dtype='object') \nlen of numeric cloumns 37 \ncategoric cloumns Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n       'SaleType', 'SaleCondition'],\n      dtype='object') \nlen of categoric cloumns 43 \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**We can see, in this dataset we have **\n1. The size of dataset: train_data:(1460, 80) and test_data:(1460, 79).\n2. The numeric columns: 37\n3. The categoric columns: 43"},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Split data\n**In this step we will split data into 3 part:**\n1. Numerical columns\n2. Categorical colmns with unique feature < 10: For OneHotEncoding\n3. Categorical columns with unique feature > 10: For LabelEncoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_col = [num for num in test_data.columns \n                 if test_data[num].dtype in ['int64','float64']]\n\ncategorical_low_col = [calow for calow in test_data.columns\n                      if test_data[calow].dtype in ['object']\n                      and test_data[calow].nunique() < 10]\ncategorical_high_col = [cahigh for cahigh in test_data.columns \n                       if test_data[cahigh].dtype in ['object']\n                       and test_data[cahigh].nunique() >= 10]\n\n# check three parts\nprint('numerical_col {}'.format(numerical_col))\nprint('len of numerical_col {}'.format(len(numerical_col)))\nprint('categorical_low_col {}'.format(categorical_low_col))\nprint('len of categorical_low_col {}'.format(len(categorical_low_col)))\nprint('categorical_high_col {}'.format(categorical_high_col))\nprint('len of categorical_high_col {}'.format(len(categorical_high_col)))","execution_count":3,"outputs":[{"output_type":"stream","text":"numerical_col ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\nlen of numerical_col 36\ncategorical_low_col ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\nlen of categorical_low_col 40\ncategorical_high_col ['Neighborhood', 'Exterior1st', 'Exterior2nd']\nlen of categorical_high_col 3\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## STEP3: Processing data\nProcessing data is important step that help your model more accurately. In this step we need\n1. create new dataset with columns that do not have too much missing values(70%)\n2. check missing data and drop columns with too much missing values\n3. Processing categorical variables and numerical variables\n4. Create input, output, test for train and test your model\n\n**we will slove 2 3 4 step by use pipe**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# drop the missing value row in out SalePrice in train_data and test_data\ntrain_data.dropna(axis=0,subset=[\"SalePrice\"],inplace=True)\n# create a output for train\ny = train_data.SalePrice\nnumerical_col_new = [numnew for numnew in numerical_col\n                    if train_data[numnew].isnull().sum() < 1000\n                    or test_data[numnew].isnull().sum() < 1000]\ncategorical_low_col_new = [calownew for calownew in categorical_low_col\n                          if train_data[calownew].isnull().sum() < 1000\n                          or test_data[calownew].isnull().sum() < 1000]\ncategorical_high_col_new = [cahighnew for cahighnew in categorical_high_col\n                          if train_data[cahighnew].isnull().sum() < 1000\n                          or test_data[cahighnew].isnull().sum() < 1000]\nmy_cols = numerical_col_new + categorical_low_col_new + categorical_high_col_new\n\n# create new dataset\ntrain_data_new = train_data[my_cols].copy()\ntest_data_new = test_data[my_cols].copy()\n\nX_train, X_valid, y_train, y_valid = train_test_split(train_data_new,\n                                                      y,train_size=0.8,\n                                                      test_size=0.2,\n                                                      random_state=0)\n\n# check three parts\nprint('numerical_col_new {}'.format(numerical_col_new))\nprint('len of numerical_col_new {}'.format(len(numerical_col_new)))\nprint('categorical_low_col_new {}'.format(categorical_low_col_new))\nprint('len of categorical_low_col_new {}'.format(len(categorical_low_col_new)))\nprint('categorical_high_col_new {}'.format(categorical_high_col_new))\nprint('len of categorical_high_col_new {}'.format(len(categorical_high_col_new)))","execution_count":4,"outputs":[{"output_type":"stream","text":"numerical_col_new ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\nlen of numerical_col_new 36\ncategorical_low_col_new ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\nlen of categorical_low_col_new 36\ncategorical_high_col_new ['Neighborhood', 'Exterior1st', 'Exterior2nd']\nlen of categorical_high_col_new 3\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**We can see**\n\nIn the categorical_low_col_new dropped 4 columns with too much missing values"},{"metadata":{},"cell_type":"markdown","source":"**Now we will use pipeline**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nimport category_encoders as ce\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# preprocessing for numerical data \nnumerical_transformer = Pipeline(verbose=False,steps=[\n    ('imputer', SimpleImputer(strategy = 'mean')),\n])\n# preprocessing for categorical data\ncategorical_low_transformer = Pipeline(verbose=False,steps=[\n    ('imputer_one_hot', SimpleImputer(strategy = 'most_frequent')),\n    ('one_hot',OneHotEncoder(handle_unknown = 'ignore'))\n])\ncategorical_high_transformer = Pipeline(verbose = False, steps=[\n    ('imputer_lable',SimpleImputer(strategy = 'most_frequent')),\n    ('lable',ce.OrdinalEncoder())])\n\n# bundle preprocessing for numerical and categorical data \npreprocessor = ColumnTransformer(verbose = False,transformers=[\n    ('num',numerical_transformer,numerical_col_new),\n    ('calow',categorical_low_transformer,categorical_low_col_new),\n    ('cahigh',categorical_high_transformer,categorical_high_col_new)])\n\nmy_pipeline = Pipeline(verbose = False, steps = [\n    ('preprocessor',preprocessor),\n    ('model',RandomForestRegressor(n_estimators=100,random_state=0))])\nmy_pipeline.fit(train_data_new,y)\ntest_preds = my_pipeline.predict(test_data_new)\n\n# find the best tree size does not good work\n# tryto = range(500)\n# values = []\n# for i in tryto:\n#     values.append(i)\n# del values[0:3]\n# def get_mae(value, X_train, X_valid, y_train, y_valid):\n#     model_test = RandomForestRegressor(n_estimators = value,random_state=0)\n#     test_pipeline = Pipeline(verbose = False, steps = [\n#         ('preprocessor',preprocessor),\n#         ('model_test',model_test)])\n#     test_pipeline.fit(X_train,y_train)\n#     predict = test_pipeline.predict(X_valid)\n#     mean = mean_absolute_error(y_valid, predict)\n#     return mean\n# compare = {value:get_mae(value,X_train, X_valid, y_train, y_valid) for value in values}    \n# best_tree_size = min(compare, key = compare.get)\n# print(best_tree_size)\n\n","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STEP4: Create submission.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'Id': test_data_new.index,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":6,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}