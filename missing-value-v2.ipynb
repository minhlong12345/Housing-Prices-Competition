{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Machine learning competitions are a great way to improve your data science skills and measure your process.\n",
    "\n",
    "In this project, you will create and submit predictions for  a kaggle competition. you can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this competition.\n",
    "\n",
    "The steps in this notebook are:\n",
    "1. Built a Random Forest model with all your data (**X** and **y**) \n",
    "2. Read in the 'test' data. which doesn't include values for the target. Predict home values in the test data with your Ramdom Forest model. \n",
    "3. Submit those predictions to the competition and see your score.\n",
    "4. optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit and see how that stack up on the competition leaderboard.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path file input:\n",
      "/kaggle/input/home-data-for-ml-course/train.csv\n",
      "/kaggle/input/home-data-for-ml-course/data_description.txt\n",
      "/kaggle/input/home-data-for-ml-course/train.csv.gz\n",
      "/kaggle/input/home-data-for-ml-course/sample_submission.csv\n",
      "/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n",
      "/kaggle/input/home-data-for-ml-course/test.csv.gz\n",
      "/kaggle/input/home-data-for-ml-course/test.csv\n",
      "The path file output:\n",
      "/kaggle/working/__notebook__.ipynb\n",
      "/kaggle/working/__output__.json\n"
     ]
    }
   ],
   "source": [
    "# this code to see the path of input and output\n",
    "import os\n",
    "print('The path file input:')\n",
    "for dirname, _,filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))\n",
    "\n",
    "print('The path file output:')\n",
    "for dirname1, _,filenames1 in os.walk('/kaggle/working'):\n",
    "    for filename1 in filenames1:\n",
    "        print(os.path.join(dirname1,filename1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "Here is the code I've written so far. start by runing it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Read data\n",
    "In this step we need:\n",
    "1. call the necessary libraries for training \n",
    "2. Read train file and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Call the libraries \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path of the file to read.\n",
    "file_path_home = '/kaggle/input/home-data-for-ml-course/train.csv'\n",
    "file_path_test = '/kaggle/input/home-data-for-ml-course/test.csv'\n",
    "home_train_data = pd.read_csv(file_path_home,index_col = 'Id')\n",
    "home_test_data = pd.read_csv(file_path_test, index_col = 'Id')\n",
    "train_data = home_train_data.copy()\n",
    "test_data = home_test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 79)\n",
      "(1460, 80)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing data\n",
    "Processing data is important step that help your model more accurately. In this step we need\n",
    "1. check missing data and drop columns with too much missing values\n",
    "2. Processing categorical variables and numerical variables\n",
    "3. Create input, output, test for train and test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the missing value row in out SalePrice in train_data and test_data\n",
    "train_data.dropna(axis=0,subset=[\"SalePrice\"],inplace=True)\n",
    "\n",
    "# Classify numerical and categorical variables\n",
    "\n",
    "# numerical columns\n",
    "numeric_col = [name for name in train_data.columns \n",
    "               if train_data[name].dtype in ['int64','float64']]\n",
    "numeric_col.remove(\"SalePrice\")\n",
    "\n",
    "# categorical columns\n",
    "categoric_col = [name1 for name1 in train_data.columns\n",
    "                if train_data[name1].dtype in ['object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
      "36\n",
      "--------------------------------------------------------------------------\n",
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(numeric_col)\n",
    "print(len(numeric_col))\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(categoric_col)\n",
    "print(len(categoric_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data of categorical variables and numerical variables\n",
    "categorical_data_train = train_data.copy()\n",
    "categorical_data_test = test_data.copy()\n",
    "numerical_data_train = train_data.copy()\n",
    "numerical_data_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_data_train: (1460, 80)\n",
      "categorical_data_test: (1459, 79)\n",
      "numerical_data_train: (1460, 80)\n",
      "numerical_data_test: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "print('categorical_data_train: {}'.format(categorical_data_train.shape))\n",
    "print('categorical_data_test: {}'.format(categorical_data_test.shape))\n",
    "print('numerical_data_train: {}'.format(numerical_data_train.shape))\n",
    "print('numerical_data_test: {}'.format(numerical_data_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code below explain: *How to solve with categorical variables***\n",
    "\n",
    "1. We will solve this problem with categorical_data_train and categorical_data_test. which I create in above code by copy dataset train_data and test_data.\n",
    "\n",
    "2. We have categorical columns in the list categoric_col.\n",
    "\n",
    "3. We need to creat a dataset only have categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing with categorical variables\n",
    "\n",
    "# craete a dataset with only categorical variables\n",
    "categorical_data_train.drop(numeric_col,axis = 1, inplace = True)\n",
    "categorical_data_train.drop([\"SalePrice\"],axis = 1, inplace = True)\n",
    "categorical_data_test.drop(numeric_col,axis = 1, inplace = True)\n",
    "\n",
    "# check missing values in each columns\n",
    "missing_train_categorical_col = [co \n",
    "    for co in categorical_data_train.columns \n",
    "                           if categorical_data_train[co].isnull().sum()> 0]\n",
    "missing_test_categorical_col = [co1 \n",
    "    for co1 in categorical_data_test.columns \n",
    "                           if categorical_data_test[co1].isnull().sum()> 0]\n",
    "a=[]\n",
    "for ch in missing_train_categorical_col:\n",
    "    a.append(ch)\n",
    "for ch1 in missing_test_categorical_col:\n",
    "    a.append(ch1)\n",
    "    \n",
    "missing_categorical_col = list(set(a))\n",
    "categorical_data_train.drop(missing_categorical_col,axis = 1, inplace = True)\n",
    "categorical_data_test.drop(missing_categorical_col,axis = 1, inplace = True)\n",
    "\n",
    "# find unique values in each columns\n",
    "label_nunique_categorical = []\n",
    "for i in categorical_data_train.columns:\n",
    "    if categorical_data_train[i].nunique() >10:\n",
    "        label_nunique_categorical.append(i)\n",
    "onehot_nunique_categorical = list(set(categorical_data_train.columns)-set(label_nunique_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_data_train: (1460, 20)\n",
      "categorical_data_test: (1459, 20)\n",
      "['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "['MSZoning', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType']\n",
      "['Neighborhood']\n",
      "1\n",
      "['LotConfig', 'LotShape', 'BldgType', 'SaleCondition', 'LandSlope', 'RoofStyle', 'RoofMatl', 'LandContour', 'ExterCond', 'HouseStyle', 'ExterQual', 'Street', 'HeatingQC', 'Foundation', 'PavedDrive', 'Heating', 'Condition1', 'CentralAir', 'Condition2']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print('categorical_data_train: {}'.format(categorical_data_train.shape))\n",
    "print('categorical_data_test: {}'.format(categorical_data_test.shape))\n",
    "print(missing_train_categorical_col)\n",
    "print(missing_test_categorical_col)\n",
    "print(label_nunique_categorical)\n",
    "print(len(label_nunique_categorical))\n",
    "print(onehot_nunique_categorical)\n",
    "print(len(onehot_nunique_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for lab in label_nunique_categorical:\n",
    "    categorical_data_train[lab] = label_encoder.fit_transform(\n",
    "        categorical_data_train[lab])\n",
    "    categorical_data_test[lab] = label_encoder.transform(\n",
    "        categorical_data_test[lab])\n",
    "\n",
    "# one_hot_encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_Encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "OH_col_train = pd.DataFrame(OH_Encoder.fit_transform(\n",
    "    categorical_data_train[onehot_nunique_categorical]))\n",
    "OH_col_test = pd.DataFrame(OH_Encoder.transform(\n",
    "    categorical_data_test[onehot_nunique_categorical]))\n",
    "\n",
    "# when use OneHotEncoder that remove index, put it back\n",
    "OH_col_train.index = categorical_data_train.index\n",
    "OH_col_test.index = categorical_data_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 20)\n",
      "(1459, 20)\n"
     ]
    }
   ],
   "source": [
    "print(categorical_data_train.shape)\n",
    "print(categorical_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop old column\n",
    "num_categorical_data_train = categorical_data_train.drop(onehot_nunique_categorical,\n",
    "                                                         axis = 1)\n",
    "num_categorical_data_test = categorical_data_test.drop(onehot_nunique_categorical,\n",
    "                                                       axis = 1)\n",
    "\n",
    "# add new cloumns\n",
    "complete_categorical_data_train = pd.concat((num_categorical_data_train,\n",
    "                                             OH_col_train),axis = 1)\n",
    "complete_categorical_data_test = pd.concat((num_categorical_data_test,\n",
    "                                            OH_col_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 1)\n",
      "(1459, 1)\n",
      "(1460, 100)\n",
      "(1459, 100)\n"
     ]
    }
   ],
   "source": [
    "print(num_categorical_data_train.shape)\n",
    "print(num_categorical_data_test.shape)\n",
    "print(complete_categorical_data_train.shape)\n",
    "print(complete_categorical_data_test.shape)\n",
    "# complete_categorical_data_train.head()\n",
    "# complete_categorical_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in here we have problem. how to combined numerical and categorical columns \n",
    "# when one of all have missing values\n",
    "# we have two the way to solve this problem\n",
    "# 1. dropping all columns have missing values\n",
    "# 2. filling with mean values for missing values\n",
    "\n",
    "\n",
    "# so we try two way and choose the most accurate model\n",
    "# for the way 2: I checked label_nunique_categorical and it can use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code below explain: *How to solve with numerical variables***\n",
    "\n",
    "1. We will solve this problem with numerical_data_train and numerical_data_test. which I create in above code by copy dataset train_data and test_data.\n",
    "\n",
    "2. We have numeric columns in the list numeric_col.\n",
    "\n",
    "3. We need to creat a dataset only have numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(numeric_col)\n",
    "print(len(numeric_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "print(numerical_data_train.shape)\n",
    "print(numerical_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(categoric_col)\n",
    "print(len(categoric_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing with numerical variables\n",
    "\n",
    "# craete a dataset with only numerical variables\n",
    "numerical_data_train.drop(categoric_col,axis = 1, inplace = True)\n",
    "numerical_data_train.drop([\"SalePrice\"],axis = 1, inplace = True)\n",
    "numerical_data_test.drop(categoric_col,axis = 1, inplace = True)\n",
    "\n",
    "# check missing values in each columns\n",
    "missing_train_numerical_col = [co2 \n",
    "    for co2 in numerical_data_train.columns \n",
    "                           if numerical_data_train[co2].isnull().sum()> 1000]\n",
    "missing_test_numerical_col = [co3 \n",
    "    for co3 in numerical_data_test.columns \n",
    "                           if numerical_data_test[co3].isnull().sum()>1000]\n",
    "b=[]\n",
    "for ch2 in missing_train_numerical_col:\n",
    "    b.append(ch2)\n",
    "for ch3 in missing_test_numerical_col:\n",
    "    b.append(ch1)\n",
    "    \n",
    "missing_numerical_col = list(set(b))\n",
    "numerical_data_train.drop(missing_numerical_col,axis = 1, inplace = True)\n",
    "numerical_data_test.drop(missing_numerical_col,axis = 1, inplace = True)\n",
    "\n",
    "#fill mean values into missing values\n",
    "complete_numerical_data_train = numerical_data_train.fillna(\n",
    "    numerical_data_train.mean())\n",
    "complete_numerical_data_test = numerical_data_test.fillna(\n",
    "    numerical_data_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_data_train: (1460, 36)\n",
      "numerical_data_test: (1459, 36)\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "complete_numerical_data_train: (1460, 36)\n",
      "complete_numerical_data_test: (1459, 36)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('numerical_data_train: {}'.format(numerical_data_train.shape))\n",
    "print('numerical_data_test: {}'.format(numerical_data_test.shape))\n",
    "print(missing_train_numerical_col)\n",
    "print(len(missing_train_numerical_col))\n",
    "print(missing_test_numerical_col)\n",
    "print(len(missing_test_numerical_col))\n",
    "print('complete_numerical_data_train: {}'\n",
    "      .format(complete_numerical_data_train.shape))\n",
    "print('complete_numerical_data_test: {}'\n",
    "      .format(complete_numerical_data_test.shape))\n",
    "print(complete_numerical_data_train.columns.isnull().sum())\n",
    "print(complete_numerical_data_test.columns.isnull().sum())\n",
    "# numerical_data_train.head()\n",
    "# numerical_data_test.head()\n",
    "# complete_numerical_data_train.head()\n",
    "# complete_numerical_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have to combine two dataset: numerical and categorical dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.concat((complete_numerical_data_train\n",
    "                           ,complete_categorical_data_train)\n",
    "                          ,axis = 1)\n",
    "dataset_test = pd.concat((complete_numerical_data_test\n",
    "                           ,complete_categorical_data_test)\n",
    "                          ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train: (1460, 136)\n",
      "dataset_test: (1459, 136)\n"
     ]
    }
   ],
   "source": [
    "print('dataset_train: {}'.format(dataset_train.shape))\n",
    "print('dataset_test: {}'.format(dataset_test.shape))\n",
    "# dataset_test.head()\n",
    "# dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3**\n",
    "\n",
    "When we have full dataset of train and test we going to make model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_train.copy()\n",
    "X_test = dataset_test.copy()\n",
    "y = train_data.SalePrice\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460,)\n",
      "(1460, 136)\n",
      "(1459, 136)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1    208500\n",
       "2    181500\n",
       "3    223500\n",
       "4    140000\n",
       "5    250000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tryto = range(1000)\n",
    "# values = []\n",
    "# for i in tryto:\n",
    "#     values.append(i)\n",
    "# del values[0:3]\n",
    "# def get_mae(value,train_X, val_X, train_y, val_y):\n",
    "#     model = RandomForestRegressor(max_leaf_nodes = value, random_state=1)\n",
    "#     model.fit(train_X,train_y)\n",
    "#     predict = model.predict(val_X)\n",
    "#     mean = mean_absolute_error(val_y, predict)\n",
    "#     return mean\n",
    "# compare = {value:get_mae(value,X_train, X_valid, y_train, y_valid) \n",
    "#            for value in values}\n",
    "# best_tree_size = min(compare, key = compare.get)\n",
    "# print(best_tree_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_model_on_full_data = RandomForestRegressor(max_leaf_nodes=195, random_state=0)\n",
    "rf_model_on_full_data.fit(X,y)\n",
    "test_preds = rf_model_on_full_data.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check missing values and drop column with too much missing values\n",
    "# missing_values = {col:train_data[col].isnull().sum()\n",
    "#                   for col in train_data.columns if train_data[col].isnull().any()}\n",
    "# missing_values_col = list(set(missing_values))\n",
    "# for i in missing_values_col:\n",
    "#     if missing_values[i] >= 1000:\n",
    "# #         print('hell')\n",
    "#         train_data.drop(i, axis= 1, inplace = True )\n",
    "# #         print('llo')\n",
    "#         test_data.drop(i, axis= 1, inplace = True )\n",
    "\n",
    "# # Processing numberical variables\n",
    "# if train_data['SalePrice'].isnull().sum() > 0:\n",
    "#     print('the SalePrice has missing values')\n",
    "#     train_data.dropna(axis = 0, subset= ['SalePrice'],inplace= True)\n",
    "# numeric_col = [name for name in train_data.columns \n",
    "#               if train_data[name].dtype in ['int64','float64']]\n",
    "# # create a array for check how many missing values in each columns\n",
    "# missing_numeric_col = [co \n",
    "#     for co in numeric_col if train_data[co].isnull().any()]\n",
    "# for drc in missing_numeric_col:\n",
    "#     if train_data[drc].isnull().sum() >= 1000:\n",
    "#         print('delete') # code to check loop\n",
    "#         train_data.drop(drc,asix = 1 , inplace = True)\n",
    "# # Processing categorical variables\n",
    "# the_categorical_column = train_data.select_dtypes(include = ['object'])\n",
    "# print(len(the_categorical_column.columns))\n",
    "# missing_categorical_column=['{}: {}'.format(nam,the_categorical_column[nam].isnull().sum())\n",
    "#                             for nam in the_categorical_column.columns \n",
    "#                             if the_categorical_column[nam].isnull().any()]\n",
    "# print(missing_categorical_column)\n",
    "# print(len(missing_categorical_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(numeric_col)\n",
    "# train_data[numeric_col].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
